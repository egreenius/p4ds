{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lesson6_Scikit.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TIXNkwnRM5M9"
      },
      "source": [
        "## Задание 1\n",
        ">*Импортируйте библиотеки pandas и numpy.\n",
        "Загрузите \"Boston House Prices dataset\" из встроенных наборов данных библиотеки sklearn. Создайте датафреймы X и y из этих данных.\n",
        "Разбейте эти датафреймы на тренировочные (X_train, y_train) и тестовые (X_test, y_test) с помощью функции train_test_split так, чтобы размер тестовой выборки\n",
        "составлял 30% от всех данных, при этом аргумент random_state должен быть равен 42.\n",
        "Создайте модель линейной регрессии под названием lr с помощью класса LinearRegression из модуля sklearn.linear_model.\n",
        "Обучите модель на тренировочных данных (используйте все признаки) и сделайте предсказание на тестовых.\n",
        "Вычислите R2 полученных предказаний с помощью r2_score из модуля sklearn.metrics.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q9sunYzsOA3N"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.datasets import load_boston"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xfZWrTovQb-T",
        "outputId": "7b339287-f6c9-4f96-b3bb-33b9b3efd131"
      },
      "source": [
        "# загрузим датасет в переменную boston\n",
        "boston = load_boston()\n",
        "print(type(boston))\n",
        "# непонятно откуда, но мы узнали что загруженный набор данных - это словарь. Смотрим ключи этого словаря\n",
        "boston.keys()\n"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'sklearn.utils.Bunch'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['data', 'target', 'feature_names', 'DESCR', 'filename'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JKbxikK_QzJG",
        "outputId": "ab1adffd-b49b-477d-97b3-50ba834c4527"
      },
      "source": [
        "# попробуем понять что это за словарь и какая в нем содержится информация\n",
        "print(boston[\"DESCR\"])"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ".. _boston_dataset:\n",
            "\n",
            "Boston house prices dataset\n",
            "---------------------------\n",
            "\n",
            "**Data Set Characteristics:**  \n",
            "\n",
            "    :Number of Instances: 506 \n",
            "\n",
            "    :Number of Attributes: 13 numeric/categorical predictive. Median Value (attribute 14) is usually the target.\n",
            "\n",
            "    :Attribute Information (in order):\n",
            "        - CRIM     per capita crime rate by town\n",
            "        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
            "        - INDUS    proportion of non-retail business acres per town\n",
            "        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
            "        - NOX      nitric oxides concentration (parts per 10 million)\n",
            "        - RM       average number of rooms per dwelling\n",
            "        - AGE      proportion of owner-occupied units built prior to 1940\n",
            "        - DIS      weighted distances to five Boston employment centres\n",
            "        - RAD      index of accessibility to radial highways\n",
            "        - TAX      full-value property-tax rate per $10,000\n",
            "        - PTRATIO  pupil-teacher ratio by town\n",
            "        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
            "        - LSTAT    % lower status of the population\n",
            "        - MEDV     Median value of owner-occupied homes in $1000's\n",
            "\n",
            "    :Missing Attribute Values: None\n",
            "\n",
            "    :Creator: Harrison, D. and Rubinfeld, D.L.\n",
            "\n",
            "This is a copy of UCI ML housing dataset.\n",
            "https://archive.ics.uci.edu/ml/machine-learning-databases/housing/\n",
            "\n",
            "\n",
            "This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\n",
            "\n",
            "The Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\n",
            "prices and the demand for clean air', J. Environ. Economics & Management,\n",
            "vol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\n",
            "...', Wiley, 1980.   N.B. Various transformations are used in the table on\n",
            "pages 244-261 of the latter.\n",
            "\n",
            "The Boston house-price data has been used in many machine learning papers that address regression\n",
            "problems.   \n",
            "     \n",
            ".. topic:: References\n",
            "\n",
            "   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\n",
            "   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ptaCq74SLVh",
        "outputId": "d9bcc42e-37c2-4cc6-f1da-d3e63559b4de"
      },
      "source": [
        "# ключ data содержит значения данных в выборке.\n",
        "data = boston[\"data\"]\n",
        "# всего получается 506 строк - для каждого объекта недвижимости, и 13 признаков\n",
        "data.shape"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(506, 13)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eBXUDTGtTC6S",
        "outputId": "aa408394-27e8-4a88-df53-6b9c9b38a660"
      },
      "source": [
        "# названия признаков - это значения ключа \"feature_names\"\n",
        "feature_names = boston[\"feature_names\"]\n",
        "# что они означают - смотрим значение ключа DESCR\n",
        "feature_names"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD',\n",
              "       'TAX', 'PTRATIO', 'B', 'LSTAT'], dtype='<U7')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qo9UCXCPUFdF",
        "outputId": "880df5ec-a7ae-47ba-9559-fa970301470d"
      },
      "source": [
        "# ключ \"target\" содержит массив целевых значений, то есть цен на недвижимость\n",
        "target = boston[\"target\"]\n",
        "target[:5]"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([24. , 21.6, 34.7, 33.4, 36.2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "MfmjbvnRVE1s",
        "outputId": "e7547eb6-1009-4727-d7f3-842115f8f19b"
      },
      "source": [
        "# создадим датафрейм из массива data. Названия колонок (признаков) возьмем из массива - feature_names\n",
        "X = pd.DataFrame(data, columns=feature_names)\n",
        "X.head()"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CRIM</th>\n",
              "      <th>ZN</th>\n",
              "      <th>INDUS</th>\n",
              "      <th>CHAS</th>\n",
              "      <th>NOX</th>\n",
              "      <th>RM</th>\n",
              "      <th>AGE</th>\n",
              "      <th>DIS</th>\n",
              "      <th>RAD</th>\n",
              "      <th>TAX</th>\n",
              "      <th>PTRATIO</th>\n",
              "      <th>B</th>\n",
              "      <th>LSTAT</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.00632</td>\n",
              "      <td>18.0</td>\n",
              "      <td>2.31</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.538</td>\n",
              "      <td>6.575</td>\n",
              "      <td>65.2</td>\n",
              "      <td>4.0900</td>\n",
              "      <td>1.0</td>\n",
              "      <td>296.0</td>\n",
              "      <td>15.3</td>\n",
              "      <td>396.90</td>\n",
              "      <td>4.98</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.02731</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.07</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.469</td>\n",
              "      <td>6.421</td>\n",
              "      <td>78.9</td>\n",
              "      <td>4.9671</td>\n",
              "      <td>2.0</td>\n",
              "      <td>242.0</td>\n",
              "      <td>17.8</td>\n",
              "      <td>396.90</td>\n",
              "      <td>9.14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.02729</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.07</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.469</td>\n",
              "      <td>7.185</td>\n",
              "      <td>61.1</td>\n",
              "      <td>4.9671</td>\n",
              "      <td>2.0</td>\n",
              "      <td>242.0</td>\n",
              "      <td>17.8</td>\n",
              "      <td>392.83</td>\n",
              "      <td>4.03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.03237</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.18</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.458</td>\n",
              "      <td>6.998</td>\n",
              "      <td>45.8</td>\n",
              "      <td>6.0622</td>\n",
              "      <td>3.0</td>\n",
              "      <td>222.0</td>\n",
              "      <td>18.7</td>\n",
              "      <td>394.63</td>\n",
              "      <td>2.94</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.06905</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.18</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.458</td>\n",
              "      <td>7.147</td>\n",
              "      <td>54.2</td>\n",
              "      <td>6.0622</td>\n",
              "      <td>3.0</td>\n",
              "      <td>222.0</td>\n",
              "      <td>18.7</td>\n",
              "      <td>396.90</td>\n",
              "      <td>5.33</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
              "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
              "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
              "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
              "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
              "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
              "\n",
              "   PTRATIO       B  LSTAT  \n",
              "0     15.3  396.90   4.98  \n",
              "1     17.8  396.90   9.14  \n",
              "2     17.8  392.83   4.03  \n",
              "3     18.7  394.63   2.94  \n",
              "4     18.7  396.90   5.33  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "0OhibdXSVi-_",
        "outputId": "4e347590-04ac-4e7a-a3b1-f11cbcdd8961"
      },
      "source": [
        "# создадим еще один датафрейм, в нем будут целевые значения. Колонку назовем - price\n",
        "y = pd.DataFrame(target, columns=[\"price\"])\n",
        "y.head()"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>price</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>24.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>21.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>34.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>33.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>36.2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   price\n",
              "0   24.0\n",
              "1   21.6\n",
              "2   34.7\n",
              "3   33.4\n",
              "4   36.2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5IQdMdimV9gl",
        "outputId": "583db805-23e8-4c1b-8a3f-341c848ddb98"
      },
      "source": [
        "# проанализируем датасеты на незаполненные или пропущенные значения\n",
        "print(X.info())\n",
        "print()\n",
        "print(y.info())\n",
        "print()\n",
        "print('Видим, что каждый признак в обеих датафреймах имеет по 506 значений. Значит незаполненных или пропущенных данных нет. Хорошо!')"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 506 entries, 0 to 505\n",
            "Data columns (total 13 columns):\n",
            " #   Column   Non-Null Count  Dtype  \n",
            "---  ------   --------------  -----  \n",
            " 0   CRIM     506 non-null    float64\n",
            " 1   ZN       506 non-null    float64\n",
            " 2   INDUS    506 non-null    float64\n",
            " 3   CHAS     506 non-null    float64\n",
            " 4   NOX      506 non-null    float64\n",
            " 5   RM       506 non-null    float64\n",
            " 6   AGE      506 non-null    float64\n",
            " 7   DIS      506 non-null    float64\n",
            " 8   RAD      506 non-null    float64\n",
            " 9   TAX      506 non-null    float64\n",
            " 10  PTRATIO  506 non-null    float64\n",
            " 11  B        506 non-null    float64\n",
            " 12  LSTAT    506 non-null    float64\n",
            "dtypes: float64(13)\n",
            "memory usage: 51.5 KB\n",
            "None\n",
            "\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 506 entries, 0 to 505\n",
            "Data columns (total 1 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   price   506 non-null    float64\n",
            "dtypes: float64(1)\n",
            "memory usage: 4.1 KB\n",
            "None\n",
            "\n",
            "Видим, что каждый признак в обеих датафреймах имеет по 506 значений. Значит незаполненных или пропущенных данных нет. Хорошо!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CH8CW4iwOA3j"
      },
      "source": [
        "# чтобы разбить нашу выборку на тренировочную и тестовую (валидационную) загрузим функции \"train_test_split\"\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SucwMIcVOA3k"
      },
      "source": [
        "# разобьем наши датафреймы на тренировочные и тестовые. Если параметр test_size от 0 до 1, то он воспринимается как доля. В противном случае как количество \n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y0r2zjWIOA3l"
      },
      "source": [
        "# загружаем модель линейной регрессии\n",
        "from sklearn.linear_model import LinearRegression"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G4CozP_dYwLS"
      },
      "source": [
        "# создаем экземпляр модели линейной  регрессии lr \n",
        "lr = LinearRegression()"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qv8I2tA-OA3m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "188b41b4-08d6-4ea8-aac5-e955fa4c8702"
      },
      "source": [
        "# обучим нашу модель с помощью метода fit\n",
        "lr.fit(X_train, y_train)"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HkWpZyLGZs1a"
      },
      "source": [
        "# Теперь, когда модель обучена, мы можем получить предсказанные значения на объектах X_test с помощью метода .predict:\n",
        "y_pred = lr.predict(X_test)"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "qfBKC_U_Z4nZ",
        "outputId": "31f10035-cae0-4de0-c83a-5ba817ad906f"
      },
      "source": [
        "# Создадим таблицу DataFrame чтобы сопоставить реальные значения с предсказанными. \n",
        "# Поскольку массив y_pred является двумерным, переведём его в одномерный, используя метод .flatten.\n",
        "check_test = pd.DataFrame({\n",
        "    \"y_test\": y_test[\"price\"],\n",
        "    \"y_pred\": y_pred.flatten(),\n",
        "})\n",
        "\n",
        "check_test.head(10)"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>y_test</th>\n",
              "      <th>y_pred</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>173</th>\n",
              "      <td>23.6</td>\n",
              "      <td>28.648960</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>274</th>\n",
              "      <td>32.4</td>\n",
              "      <td>36.495014</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>491</th>\n",
              "      <td>13.6</td>\n",
              "      <td>15.411193</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>72</th>\n",
              "      <td>22.8</td>\n",
              "      <td>25.403213</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>452</th>\n",
              "      <td>16.1</td>\n",
              "      <td>18.855280</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76</th>\n",
              "      <td>20.0</td>\n",
              "      <td>23.146689</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>316</th>\n",
              "      <td>17.8</td>\n",
              "      <td>17.392124</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>140</th>\n",
              "      <td>14.0</td>\n",
              "      <td>14.078599</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>471</th>\n",
              "      <td>19.6</td>\n",
              "      <td>23.036927</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>500</th>\n",
              "      <td>16.8</td>\n",
              "      <td>20.599433</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     y_test     y_pred\n",
              "173    23.6  28.648960\n",
              "274    32.4  36.495014\n",
              "491    13.6  15.411193\n",
              "72     22.8  25.403213\n",
              "452    16.1  18.855280\n",
              "76     20.0  23.146689\n",
              "316    17.8  17.392124\n",
              "140    14.0  14.078599\n",
              "471    19.6  23.036927\n",
              "500    16.8  20.599433"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "beNG_vdPa-4b"
      },
      "source": [
        "from sklearn.metrics import r2_score"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u5L4mIuvbe3j",
        "outputId": "2fb2e2a8-ef34-440c-facc-289f31494037"
      },
      "source": [
        "R2 = r2_score(y_test, y_pred)\n",
        "R2"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7112260057484974"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fmvLkYdRs2xm"
      },
      "source": [
        "## Задание 2\n",
        ">*Создайте модель под названием model с помощью RandomForestRegressor из модуля sklearn.ensemble.\n",
        "Сделайте агрумент n_estimators равным 1000,\n",
        "max_depth должен быть равен 12 и random_state сделайте равным 42.\n",
        "Обучите модель на тренировочных данных аналогично тому, как вы обучали модель LinearRegression,\n",
        "но при этом в метод fit вместо датафрейма y_train поставьте y_train.values[:, 0],\n",
        "чтобы получить из датафрейма одномерный массив Numpy,\n",
        "так как для класса RandomForestRegressor в данном методе для аргумента y предпочтительно применение массивов вместо датафрейма.\n",
        "Сделайте предсказание на тестовых данных и посчитайте R2. Сравните с результатом из предыдущего задания.\n",
        "Напишите в комментариях к коду, какая модель в данном случае работает лучше.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3g2001bOA4t"
      },
      "source": [
        "from sklearn.ensemble import RandomForestRegressor"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dU8bXGhsEQQn"
      },
      "source": [
        "from sklearn.metrics import r2_score"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fm9ldJKcCwSJ",
        "outputId": "bf982625-89bd-4e7e-e3e3-2ff36ce1da2b"
      },
      "source": [
        "model = RandomForestRegressor(n_estimators=1000, max_depth=12, random_state=42)\n",
        "model.fit(X_train, y_train.values[:,0])\n",
        "y_pred = model.predict(X_test)\n",
        "R2 = r2_score(y_test, y_pred)\n",
        "R2\n"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8749965273218174"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gdKHOpBBY6mA"
      },
      "source": [
        "Для модели LinearRegression мы получили коэфициент R2 = 0,71. Для модели RandomForestRegressor мы получили коэфициент R2 = 0,875, что **значительно** лучше"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ohLXsScfZ9H5"
      },
      "source": [
        "## Задание 3\n",
        ">*Вызовите документацию для класса RandomForestRegressor,\n",
        "найдите информацию об атрибуте feature_importances_.\n",
        "С помощью этого атрибута найдите сумму всех показателей важности,\n",
        "установите, какие два признака показывают наибольшую важность.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "71386QpqaN-3",
        "outputId": "94774ae8-af22-45ad-d7bb-1067a17ac2d9"
      },
      "source": [
        "# посмотрим на аттрибут feature_importance_ . Похоже, что этот аттрибут содержит информацию\n",
        "# об индексе важности каждого признака, то есть насколько каждый признак в итоге влияет на оценку для конкретного состояния обучения\n",
        "model.feature_importances_"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.03211748, 0.00154999, 0.0070941 , 0.0011488 , 0.01436832,\n",
              "       0.40270459, 0.01424477, 0.06403265, 0.00496762, 0.01169177,\n",
              "       0.01808961, 0.0123114 , 0.41567892])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lfiCB6hofS_K",
        "outputId": "4c725937-9375-4ade-a2f0-7720642a2e54"
      },
      "source": [
        "# я так понял, что нужно найти сумму всех feature_importances_. Предположительно, она должна быть равна 1.\n",
        "s_f = model.feature_importances_.sum()\n",
        "print(f'Сумма всех показателей важности = {s_f}')"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Сумма всех показателей важности = 0.9999999999999999\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "TXoapFm0h6lv",
        "outputId": "06216e11-262a-4e28-ad73-a90a9ef4f1a7"
      },
      "source": [
        "# создадим датафрейм содержащий признаки и индекс их влияния (важности)\n",
        "important_features = pd.DataFrame({\n",
        "    \"feature\": boston[\"feature_names\"],\n",
        "    \"importance_ind\": model.feature_importances_,\n",
        "})\n",
        "important_features"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>feature</th>\n",
              "      <th>importance_ind</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CRIM</td>\n",
              "      <td>0.032117</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ZN</td>\n",
              "      <td>0.001550</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>INDUS</td>\n",
              "      <td>0.007094</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>CHAS</td>\n",
              "      <td>0.001149</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NOX</td>\n",
              "      <td>0.014368</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>RM</td>\n",
              "      <td>0.402705</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>AGE</td>\n",
              "      <td>0.014245</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>DIS</td>\n",
              "      <td>0.064033</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>RAD</td>\n",
              "      <td>0.004968</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>TAX</td>\n",
              "      <td>0.011692</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>PTRATIO</td>\n",
              "      <td>0.018090</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>B</td>\n",
              "      <td>0.012311</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>LSTAT</td>\n",
              "      <td>0.415679</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    feature  importance_ind\n",
              "0      CRIM        0.032117\n",
              "1        ZN        0.001550\n",
              "2     INDUS        0.007094\n",
              "3      CHAS        0.001149\n",
              "4       NOX        0.014368\n",
              "5        RM        0.402705\n",
              "6       AGE        0.014245\n",
              "7       DIS        0.064033\n",
              "8       RAD        0.004968\n",
              "9       TAX        0.011692\n",
              "10  PTRATIO        0.018090\n",
              "11        B        0.012311\n",
              "12    LSTAT        0.415679"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "id": "c5YKdzB0jkIN",
        "outputId": "64d69986-251e-4c94-9586-76951dce9110"
      },
      "source": [
        "# отсортируем датафрейм по индексу влияния от большего к меньшему, и возьмем первые два значения\n",
        "# это будут два наиболее важных признака\n",
        "important_features.sort_values(by=\"importance_ind\", inplace=True, ascending=False)\n",
        "print('Два, наиболее влиятельных (важных) признака: ')\n",
        "important_features[:2]"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Два, наиболее влиятельных (важных) признака: \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>feature</th>\n",
              "      <th>importance_ind</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>LSTAT</td>\n",
              "      <td>0.415679</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>RM</td>\n",
              "      <td>0.402705</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   feature  importance_ind\n",
              "12   LSTAT        0.415679\n",
              "5       RM        0.402705"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OS51r3hUpWo5"
      },
      "source": [
        "## Задание 4\n",
        ">*В этом задании мы будем работать с датасетом, с которым мы уже знакомы по домашнему заданию по библиотеке Matplotlib, это датасет Credit Card Fraud Detection.Для этого датасета мы будем решать задачу классификации - будем определять,какие из транзакциции по кредитной карте являются мошенническими.Данный датасет сильно несбалансирован (так как случаи мошенничества относительно редки),так что применение метрики accuracy не принесет пользы и не поможет выбрать лучшую модель.Мы будем вычислять AUC, то есть площадь под кривой ROC.\n",
        "Импортируйте из соответствующих модулей RandomForestClassifier, GridSearchCV и train_test_split.\n",
        "Загрузите датасет creditcard.csv и создайте датафрейм df.\n",
        "С помощью метода value_counts с аргументом normalize=True убедитесь в том, что выборка несбалансирована.Используя метод info, проверьте, все ли столбцы содержат числовые данные и нет ли в них пропусков.Примените следующую настройку, чтобы можно было просматривать все столбцы датафрейма:\n",
        "pd.options.display.max_columns = 100.\n",
        "Просмотрите первые 10 строк датафрейма df.\n",
        "Создайте датафрейм X из датафрейма df, исключив столбец Class.\n",
        "Создайте объект Series под названием y из столбца Class.\n",
        "Разбейте X и y на тренировочный и тестовый наборы данных при помощи функции train_test_split, используя аргументы: test_size=0.3, random_state=100, stratify=y.\n",
        "У вас должны получиться объекты X_train, X_test, y_train и y_test.\n",
        "Просмотрите информацию о их форме.\n",
        "Для поиска по сетке параметров задайте такие параметры:\n",
        "parameters = [{'n_estimators': [10, 15],\n",
        "'max_features': np.arange(3, 5),\n",
        "'max_depth': np.arange(4, 7)}]\n",
        "Создайте модель GridSearchCV со следующими аргументами:\n",
        "estimator=RandomForestClassifier(random_state=100),\n",
        "param_grid=parameters,\n",
        "scoring='roc_auc',\n",
        "cv=3.\n",
        "Обучите модель на тренировочном наборе данных (может занять несколько минут).\n",
        "Просмотрите параметры лучшей модели с помощью атрибута best_params_.\n",
        "Предскажите вероятности классов с помощью полученнной модели и метода predict_proba.\n",
        "Из полученного результата (массив Numpy) выберите столбец с индексом 1 (вероятность класса 1) и запишите в массив y_pred_proba. Из модуля sklearn.metrics импортируйте метрику roc_auc_score.\n",
        "Вычислите AUC на тестовых данных и сравните с результатом,полученным на тренировочных данных, используя в качестве аргументов массивы y_test и y_pred_proba.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8UYC_RSJqvrt"
      },
      "source": [
        "# загружаем необходимые модули\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JpyEmr9ytv-7"
      },
      "source": [
        ""
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Owuu9MYssvTP"
      },
      "source": [
        "# загружаем датасет creditcard.csv\n",
        "url = \"/content/drive/MyDrive/Образование/Факультет ИИ/Библиотеки Python для Data Science: Numpy, Matplotlib, Scikit-learn/creditcard.csv\"\n",
        "# url = \"creditcard.csv\"\n",
        "df = pd.read_csv(url)\n"
      ],
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZizbgeJ6vkgM",
        "outputId": "2b10cadd-200f-4655-a2a4-566340379e92"
      },
      "source": [
        "# Признак Class определяет тип операции: 0 - обычная, 1 - мошенчиеская. Параметр normalize=True - вычисляет относительную гистограмму.\n",
        "# В данном случае, если normalize=False - будут показаны количества операций каждого типа, если True - доля операций \n",
        "df.Class.value_counts(normalize=True)"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    0.998273\n",
              "1    0.001727\n",
              "Name: Class, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F1VlT-sX2G1X"
      },
      "source": [
        "Мы получили, что доля обычных операций практически равна 100%, и очень малая часть, около 0,1% операции признаны мошенническими. То есть выборка явно несбалансирована"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GM3gen0K2pEl",
        "outputId": "0ddc8dae-9ea5-4f0a-a04c-b97ec70a65a4"
      },
      "source": [
        "df.info()\n"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 284807 entries, 0 to 284806\n",
            "Data columns (total 31 columns):\n",
            " #   Column  Non-Null Count   Dtype  \n",
            "---  ------  --------------   -----  \n",
            " 0   Time    284807 non-null  float64\n",
            " 1   V1      284807 non-null  float64\n",
            " 2   V2      284807 non-null  float64\n",
            " 3   V3      284807 non-null  float64\n",
            " 4   V4      284807 non-null  float64\n",
            " 5   V5      284807 non-null  float64\n",
            " 6   V6      284807 non-null  float64\n",
            " 7   V7      284807 non-null  float64\n",
            " 8   V8      284807 non-null  float64\n",
            " 9   V9      284807 non-null  float64\n",
            " 10  V10     284807 non-null  float64\n",
            " 11  V11     284807 non-null  float64\n",
            " 12  V12     284807 non-null  float64\n",
            " 13  V13     284807 non-null  float64\n",
            " 14  V14     284807 non-null  float64\n",
            " 15  V15     284807 non-null  float64\n",
            " 16  V16     284807 non-null  float64\n",
            " 17  V17     284807 non-null  float64\n",
            " 18  V18     284807 non-null  float64\n",
            " 19  V19     284807 non-null  float64\n",
            " 20  V20     284807 non-null  float64\n",
            " 21  V21     284807 non-null  float64\n",
            " 22  V22     284807 non-null  float64\n",
            " 23  V23     284807 non-null  float64\n",
            " 24  V24     284807 non-null  float64\n",
            " 25  V25     284807 non-null  float64\n",
            " 26  V26     284807 non-null  float64\n",
            " 27  V27     284807 non-null  float64\n",
            " 28  V28     284807 non-null  float64\n",
            " 29  Amount  284807 non-null  float64\n",
            " 30  Class   284807 non-null  int64  \n",
            "dtypes: float64(30), int64(1)\n",
            "memory usage: 67.4 MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WzpTpCV325Jc"
      },
      "source": [
        "В нашем наборе данных все столбцы имеют числовой тип данных и пропусков не наблюдается.\n",
        "Уменьшим занимаемый датасетом объем оперативной памяти."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dmyHgQYovvY2"
      },
      "source": [
        "def reduce_mem_usage(df):\n",
        "    \"\"\" iterate through all the columns of a dataframe and modify the data type\n",
        "        to reduce memory usage.        \n",
        "    \"\"\"\n",
        "    start_mem = df.memory_usage().sum() / 1024**2\n",
        "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
        "    \n",
        "    for col in df.columns:\n",
        "        col_type = df[col].dtype\n",
        "        \n",
        "        if col_type != object:\n",
        "            c_min = df[col].min()\n",
        "            c_max = df[col].max()\n",
        "            if str(col_type)[:3] == 'int':\n",
        "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
        "                    df[col] = df[col].astype(np.int8)\n",
        "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
        "                    df[col] = df[col].astype(np.int16)\n",
        "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
        "                    df[col] = df[col].astype(np.int32)\n",
        "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
        "                    df[col] = df[col].astype(np.int64)  \n",
        "            else:\n",
        "                if c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
        "                    df[col] = df[col].astype(np.float32)\n",
        "                else:\n",
        "                    df[col] = df[col].astype(np.float64)\n",
        "        else:\n",
        "            df[col] = df[col].astype('category')\n",
        "\n",
        "    end_mem = df.memory_usage().sum() / 1024**2\n",
        "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
        "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
        "    \n",
        "    return df"
      ],
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hV7cEdYs3pgy",
        "outputId": "12297be8-21d9-44eb-9126-dc1e2c3c0e01"
      },
      "source": [
        "# уменьшаем размер занимаемой датасетом оперативной памяти\n",
        "df = reduce_mem_usage(df)"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Memory usage of dataframe is 67.36 MB\n",
            "Memory usage after optimization is: 32.87 MB\n",
            "Decreased by 51.2%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 379
        },
        "id": "1_dA_O324KHn",
        "outputId": "fbf001b4-ac4c-4d92-fc72-67af2f7bca66"
      },
      "source": [
        "# настраиваем кол-во отображаемых столбцов\n",
        "pd.options.display.max_columns = 100\n",
        "df.head(10)"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>V10</th>\n",
              "      <th>V11</th>\n",
              "      <th>V12</th>\n",
              "      <th>V13</th>\n",
              "      <th>V14</th>\n",
              "      <th>V15</th>\n",
              "      <th>V16</th>\n",
              "      <th>V17</th>\n",
              "      <th>V18</th>\n",
              "      <th>V19</th>\n",
              "      <th>V20</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.359807</td>\n",
              "      <td>-0.072781</td>\n",
              "      <td>2.536347</td>\n",
              "      <td>1.378155</td>\n",
              "      <td>-0.338321</td>\n",
              "      <td>0.462388</td>\n",
              "      <td>0.239599</td>\n",
              "      <td>0.098698</td>\n",
              "      <td>0.363787</td>\n",
              "      <td>0.090794</td>\n",
              "      <td>-0.551600</td>\n",
              "      <td>-0.617801</td>\n",
              "      <td>-0.991390</td>\n",
              "      <td>-0.311169</td>\n",
              "      <td>1.468177</td>\n",
              "      <td>-0.470401</td>\n",
              "      <td>0.207971</td>\n",
              "      <td>0.025791</td>\n",
              "      <td>0.403993</td>\n",
              "      <td>0.251412</td>\n",
              "      <td>-0.018307</td>\n",
              "      <td>0.277838</td>\n",
              "      <td>-0.110474</td>\n",
              "      <td>0.066928</td>\n",
              "      <td>0.128539</td>\n",
              "      <td>-0.189115</td>\n",
              "      <td>0.133558</td>\n",
              "      <td>-0.021053</td>\n",
              "      <td>149.619995</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.191857</td>\n",
              "      <td>0.266151</td>\n",
              "      <td>0.166480</td>\n",
              "      <td>0.448154</td>\n",
              "      <td>0.060018</td>\n",
              "      <td>-0.082361</td>\n",
              "      <td>-0.078803</td>\n",
              "      <td>0.085102</td>\n",
              "      <td>-0.255425</td>\n",
              "      <td>-0.166974</td>\n",
              "      <td>1.612727</td>\n",
              "      <td>1.065235</td>\n",
              "      <td>0.489095</td>\n",
              "      <td>-0.143772</td>\n",
              "      <td>0.635558</td>\n",
              "      <td>0.463917</td>\n",
              "      <td>-0.114805</td>\n",
              "      <td>-0.183361</td>\n",
              "      <td>-0.145783</td>\n",
              "      <td>-0.069083</td>\n",
              "      <td>-0.225775</td>\n",
              "      <td>-0.638672</td>\n",
              "      <td>0.101288</td>\n",
              "      <td>-0.339846</td>\n",
              "      <td>0.167170</td>\n",
              "      <td>0.125895</td>\n",
              "      <td>-0.008983</td>\n",
              "      <td>0.014724</td>\n",
              "      <td>2.690000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.358354</td>\n",
              "      <td>-1.340163</td>\n",
              "      <td>1.773209</td>\n",
              "      <td>0.379780</td>\n",
              "      <td>-0.503198</td>\n",
              "      <td>1.800499</td>\n",
              "      <td>0.791461</td>\n",
              "      <td>0.247676</td>\n",
              "      <td>-1.514654</td>\n",
              "      <td>0.207643</td>\n",
              "      <td>0.624501</td>\n",
              "      <td>0.066084</td>\n",
              "      <td>0.717293</td>\n",
              "      <td>-0.165946</td>\n",
              "      <td>2.345865</td>\n",
              "      <td>-2.890083</td>\n",
              "      <td>1.109969</td>\n",
              "      <td>-0.121359</td>\n",
              "      <td>-2.261857</td>\n",
              "      <td>0.524980</td>\n",
              "      <td>0.247998</td>\n",
              "      <td>0.771679</td>\n",
              "      <td>0.909412</td>\n",
              "      <td>-0.689281</td>\n",
              "      <td>-0.327642</td>\n",
              "      <td>-0.139097</td>\n",
              "      <td>-0.055353</td>\n",
              "      <td>-0.059752</td>\n",
              "      <td>378.660004</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.966272</td>\n",
              "      <td>-0.185226</td>\n",
              "      <td>1.792993</td>\n",
              "      <td>-0.863291</td>\n",
              "      <td>-0.010309</td>\n",
              "      <td>1.247203</td>\n",
              "      <td>0.237609</td>\n",
              "      <td>0.377436</td>\n",
              "      <td>-1.387024</td>\n",
              "      <td>-0.054952</td>\n",
              "      <td>-0.226487</td>\n",
              "      <td>0.178228</td>\n",
              "      <td>0.507757</td>\n",
              "      <td>-0.287924</td>\n",
              "      <td>-0.631418</td>\n",
              "      <td>-1.059647</td>\n",
              "      <td>-0.684093</td>\n",
              "      <td>1.965775</td>\n",
              "      <td>-1.232622</td>\n",
              "      <td>-0.208038</td>\n",
              "      <td>-0.108300</td>\n",
              "      <td>0.005274</td>\n",
              "      <td>-0.190321</td>\n",
              "      <td>-1.175575</td>\n",
              "      <td>0.647376</td>\n",
              "      <td>-0.221929</td>\n",
              "      <td>0.062723</td>\n",
              "      <td>0.061458</td>\n",
              "      <td>123.500000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.0</td>\n",
              "      <td>-1.158233</td>\n",
              "      <td>0.877737</td>\n",
              "      <td>1.548718</td>\n",
              "      <td>0.403034</td>\n",
              "      <td>-0.407193</td>\n",
              "      <td>0.095921</td>\n",
              "      <td>0.592941</td>\n",
              "      <td>-0.270533</td>\n",
              "      <td>0.817739</td>\n",
              "      <td>0.753074</td>\n",
              "      <td>-0.822843</td>\n",
              "      <td>0.538196</td>\n",
              "      <td>1.345852</td>\n",
              "      <td>-1.119670</td>\n",
              "      <td>0.175121</td>\n",
              "      <td>-0.451449</td>\n",
              "      <td>-0.237033</td>\n",
              "      <td>-0.038195</td>\n",
              "      <td>0.803487</td>\n",
              "      <td>0.408542</td>\n",
              "      <td>-0.009431</td>\n",
              "      <td>0.798279</td>\n",
              "      <td>-0.137458</td>\n",
              "      <td>0.141267</td>\n",
              "      <td>-0.206010</td>\n",
              "      <td>0.502292</td>\n",
              "      <td>0.219422</td>\n",
              "      <td>0.215153</td>\n",
              "      <td>69.989998</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2.0</td>\n",
              "      <td>-0.425966</td>\n",
              "      <td>0.960523</td>\n",
              "      <td>1.141109</td>\n",
              "      <td>-0.168252</td>\n",
              "      <td>0.420987</td>\n",
              "      <td>-0.029728</td>\n",
              "      <td>0.476201</td>\n",
              "      <td>0.260314</td>\n",
              "      <td>-0.568671</td>\n",
              "      <td>-0.371407</td>\n",
              "      <td>1.341262</td>\n",
              "      <td>0.359894</td>\n",
              "      <td>-0.358091</td>\n",
              "      <td>-0.137134</td>\n",
              "      <td>0.517617</td>\n",
              "      <td>0.401726</td>\n",
              "      <td>-0.058133</td>\n",
              "      <td>0.068653</td>\n",
              "      <td>-0.033194</td>\n",
              "      <td>0.084968</td>\n",
              "      <td>-0.208254</td>\n",
              "      <td>-0.559825</td>\n",
              "      <td>-0.026398</td>\n",
              "      <td>-0.371427</td>\n",
              "      <td>-0.232794</td>\n",
              "      <td>0.105915</td>\n",
              "      <td>0.253844</td>\n",
              "      <td>0.081080</td>\n",
              "      <td>3.670000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>4.0</td>\n",
              "      <td>1.229658</td>\n",
              "      <td>0.141004</td>\n",
              "      <td>0.045371</td>\n",
              "      <td>1.202613</td>\n",
              "      <td>0.191881</td>\n",
              "      <td>0.272708</td>\n",
              "      <td>-0.005159</td>\n",
              "      <td>0.081213</td>\n",
              "      <td>0.464960</td>\n",
              "      <td>-0.099254</td>\n",
              "      <td>-1.416907</td>\n",
              "      <td>-0.153826</td>\n",
              "      <td>-0.751063</td>\n",
              "      <td>0.167372</td>\n",
              "      <td>0.050144</td>\n",
              "      <td>-0.443587</td>\n",
              "      <td>0.002821</td>\n",
              "      <td>-0.611987</td>\n",
              "      <td>-0.045575</td>\n",
              "      <td>-0.219633</td>\n",
              "      <td>-0.167716</td>\n",
              "      <td>-0.270710</td>\n",
              "      <td>-0.154104</td>\n",
              "      <td>-0.780055</td>\n",
              "      <td>0.750137</td>\n",
              "      <td>-0.257237</td>\n",
              "      <td>0.034507</td>\n",
              "      <td>0.005168</td>\n",
              "      <td>4.990000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7.0</td>\n",
              "      <td>-0.644269</td>\n",
              "      <td>1.417964</td>\n",
              "      <td>1.074380</td>\n",
              "      <td>-0.492199</td>\n",
              "      <td>0.948934</td>\n",
              "      <td>0.428118</td>\n",
              "      <td>1.120631</td>\n",
              "      <td>-3.807864</td>\n",
              "      <td>0.615375</td>\n",
              "      <td>1.249376</td>\n",
              "      <td>-0.619468</td>\n",
              "      <td>0.291474</td>\n",
              "      <td>1.757964</td>\n",
              "      <td>-1.323865</td>\n",
              "      <td>0.686132</td>\n",
              "      <td>-0.076127</td>\n",
              "      <td>-1.222127</td>\n",
              "      <td>-0.358222</td>\n",
              "      <td>0.324505</td>\n",
              "      <td>-0.156742</td>\n",
              "      <td>1.943465</td>\n",
              "      <td>-1.015455</td>\n",
              "      <td>0.057504</td>\n",
              "      <td>-0.649709</td>\n",
              "      <td>-0.415267</td>\n",
              "      <td>-0.051634</td>\n",
              "      <td>-1.206921</td>\n",
              "      <td>-1.085339</td>\n",
              "      <td>40.799999</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>7.0</td>\n",
              "      <td>-0.894286</td>\n",
              "      <td>0.286157</td>\n",
              "      <td>-0.113192</td>\n",
              "      <td>-0.271526</td>\n",
              "      <td>2.669599</td>\n",
              "      <td>3.721818</td>\n",
              "      <td>0.370145</td>\n",
              "      <td>0.851084</td>\n",
              "      <td>-0.392048</td>\n",
              "      <td>-0.410430</td>\n",
              "      <td>-0.705117</td>\n",
              "      <td>-0.110452</td>\n",
              "      <td>-0.286254</td>\n",
              "      <td>0.074355</td>\n",
              "      <td>-0.328783</td>\n",
              "      <td>-0.210077</td>\n",
              "      <td>-0.499768</td>\n",
              "      <td>0.118765</td>\n",
              "      <td>0.570328</td>\n",
              "      <td>0.052736</td>\n",
              "      <td>-0.073425</td>\n",
              "      <td>-0.268092</td>\n",
              "      <td>-0.204233</td>\n",
              "      <td>1.011592</td>\n",
              "      <td>0.373205</td>\n",
              "      <td>-0.384157</td>\n",
              "      <td>0.011747</td>\n",
              "      <td>0.142404</td>\n",
              "      <td>93.199997</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9.0</td>\n",
              "      <td>-0.338262</td>\n",
              "      <td>1.119593</td>\n",
              "      <td>1.044367</td>\n",
              "      <td>-0.222187</td>\n",
              "      <td>0.499361</td>\n",
              "      <td>-0.246761</td>\n",
              "      <td>0.651583</td>\n",
              "      <td>0.069539</td>\n",
              "      <td>-0.736727</td>\n",
              "      <td>-0.366846</td>\n",
              "      <td>1.017614</td>\n",
              "      <td>0.836390</td>\n",
              "      <td>1.006844</td>\n",
              "      <td>-0.443523</td>\n",
              "      <td>0.150219</td>\n",
              "      <td>0.739453</td>\n",
              "      <td>-0.540980</td>\n",
              "      <td>0.476677</td>\n",
              "      <td>0.451773</td>\n",
              "      <td>0.203711</td>\n",
              "      <td>-0.246914</td>\n",
              "      <td>-0.633753</td>\n",
              "      <td>-0.120794</td>\n",
              "      <td>-0.385050</td>\n",
              "      <td>-0.069733</td>\n",
              "      <td>0.094199</td>\n",
              "      <td>0.246219</td>\n",
              "      <td>0.083076</td>\n",
              "      <td>3.680000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
              "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
              "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
              "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
              "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
              "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
              "5   2.0 -0.425966  0.960523  1.141109 -0.168252  0.420987 -0.029728  0.476201   \n",
              "6   4.0  1.229658  0.141004  0.045371  1.202613  0.191881  0.272708 -0.005159   \n",
              "7   7.0 -0.644269  1.417964  1.074380 -0.492199  0.948934  0.428118  1.120631   \n",
              "8   7.0 -0.894286  0.286157 -0.113192 -0.271526  2.669599  3.721818  0.370145   \n",
              "9   9.0 -0.338262  1.119593  1.044367 -0.222187  0.499361 -0.246761  0.651583   \n",
              "\n",
              "         V8        V9       V10       V11       V12       V13       V14  \\\n",
              "0  0.098698  0.363787  0.090794 -0.551600 -0.617801 -0.991390 -0.311169   \n",
              "1  0.085102 -0.255425 -0.166974  1.612727  1.065235  0.489095 -0.143772   \n",
              "2  0.247676 -1.514654  0.207643  0.624501  0.066084  0.717293 -0.165946   \n",
              "3  0.377436 -1.387024 -0.054952 -0.226487  0.178228  0.507757 -0.287924   \n",
              "4 -0.270533  0.817739  0.753074 -0.822843  0.538196  1.345852 -1.119670   \n",
              "5  0.260314 -0.568671 -0.371407  1.341262  0.359894 -0.358091 -0.137134   \n",
              "6  0.081213  0.464960 -0.099254 -1.416907 -0.153826 -0.751063  0.167372   \n",
              "7 -3.807864  0.615375  1.249376 -0.619468  0.291474  1.757964 -1.323865   \n",
              "8  0.851084 -0.392048 -0.410430 -0.705117 -0.110452 -0.286254  0.074355   \n",
              "9  0.069539 -0.736727 -0.366846  1.017614  0.836390  1.006844 -0.443523   \n",
              "\n",
              "        V15       V16       V17       V18       V19       V20       V21  \\\n",
              "0  1.468177 -0.470401  0.207971  0.025791  0.403993  0.251412 -0.018307   \n",
              "1  0.635558  0.463917 -0.114805 -0.183361 -0.145783 -0.069083 -0.225775   \n",
              "2  2.345865 -2.890083  1.109969 -0.121359 -2.261857  0.524980  0.247998   \n",
              "3 -0.631418 -1.059647 -0.684093  1.965775 -1.232622 -0.208038 -0.108300   \n",
              "4  0.175121 -0.451449 -0.237033 -0.038195  0.803487  0.408542 -0.009431   \n",
              "5  0.517617  0.401726 -0.058133  0.068653 -0.033194  0.084968 -0.208254   \n",
              "6  0.050144 -0.443587  0.002821 -0.611987 -0.045575 -0.219633 -0.167716   \n",
              "7  0.686132 -0.076127 -1.222127 -0.358222  0.324505 -0.156742  1.943465   \n",
              "8 -0.328783 -0.210077 -0.499768  0.118765  0.570328  0.052736 -0.073425   \n",
              "9  0.150219  0.739453 -0.540980  0.476677  0.451773  0.203711 -0.246914   \n",
              "\n",
              "        V22       V23       V24       V25       V26       V27       V28  \\\n",
              "0  0.277838 -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053   \n",
              "1 -0.638672  0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724   \n",
              "2  0.771679  0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752   \n",
              "3  0.005274 -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458   \n",
              "4  0.798279 -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   \n",
              "5 -0.559825 -0.026398 -0.371427 -0.232794  0.105915  0.253844  0.081080   \n",
              "6 -0.270710 -0.154104 -0.780055  0.750137 -0.257237  0.034507  0.005168   \n",
              "7 -1.015455  0.057504 -0.649709 -0.415267 -0.051634 -1.206921 -1.085339   \n",
              "8 -0.268092 -0.204233  1.011592  0.373205 -0.384157  0.011747  0.142404   \n",
              "9 -0.633753 -0.120794 -0.385050 -0.069733  0.094199  0.246219  0.083076   \n",
              "\n",
              "       Amount  Class  \n",
              "0  149.619995      0  \n",
              "1    2.690000      0  \n",
              "2  378.660004      0  \n",
              "3  123.500000      0  \n",
              "4   69.989998      0  \n",
              "5    3.670000      0  \n",
              "6    4.990000      0  \n",
              "7   40.799999      0  \n",
              "8   93.199997      0  \n",
              "9    3.680000      0  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5rmz_abC5a6L",
        "outputId": "a2138d22-407c-42d1-8132-f7334f5b2c5b"
      },
      "source": [
        "# создаем датафрейм X исключив столбец Class (он последний)\n",
        "X = df.iloc[:, :-1]\n",
        "# Каждый отдельный столбец датафрейма представляет собой объект Series. \n",
        "y = df.Class\n",
        "# Разбиваем наш набор данных на тренировочный и тестовый\n",
        "# что значит параметр stratify=y?\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=100, stratify=y)\n",
        "print(f'Форма X_train = {X_train.shape}, X_test = {X_test.shape}, y_train = {y_train.shape}, y_test = {y_test.shape}')"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Форма X_train = (199364, 30), X_test = (85443, 30), y_train = (199364,), y_test = (85443,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v-l92j8OI8zz"
      },
      "source": [
        "# Задаем параметры для поиска наилучших значений. (Почему мы берем такие?!)\n",
        "parameters = [{'n_estimators': [10, 15], 'max_features': np.arange(3, 5), 'max_depth': np.arange(4, 7)}]\n",
        "clf = GridSearchCV(\n",
        "    estimator=RandomForestClassifier(random_state=100),\n",
        "    param_grid=parameters,\n",
        "    scoring='roc_auc',\n",
        "    cv=3,\n",
        ")\n",
        "\n"
      ],
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vtttPk_Ya86H",
        "outputId": "6b7e6008-ea56-4984-8816-e67742a86513"
      },
      "source": [
        "# обучаем модель\n",
        "clf.fit(X_train, y_train)\n"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=3, error_score=nan,\n",
              "             estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
              "                                              class_weight=None,\n",
              "                                              criterion='gini', max_depth=None,\n",
              "                                              max_features='auto',\n",
              "                                              max_leaf_nodes=None,\n",
              "                                              max_samples=None,\n",
              "                                              min_impurity_decrease=0.0,\n",
              "                                              min_impurity_split=None,\n",
              "                                              min_samples_leaf=1,\n",
              "                                              min_samples_split=2,\n",
              "                                              min_weight_fraction_leaf=0.0,\n",
              "                                              n_estimators=100, n_jobs=None,\n",
              "                                              oob_score=False, random_state=100,\n",
              "                                              verbose=0, warm_start=False),\n",
              "             iid='deprecated', n_jobs=None,\n",
              "             param_grid=[{'max_depth': array([4, 5, 6]),\n",
              "                          'max_features': array([3, 4]),\n",
              "                          'n_estimators': [10, 15]}],\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring='roc_auc', verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sAslPyWcZ7xB",
        "outputId": "8852ff6b-430b-40ec-c11c-3fa98108a534"
      },
      "source": [
        "# смотрим, какие параметры оказались для модели наилучшими\n",
        "clf.best_params_"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'max_depth': 6, 'max_features': 3, 'n_estimators': 15}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RHj0OorgciC1",
        "outputId": "02492ae8-857b-4086-8cd5-d2cf2af6e7e4"
      },
      "source": [
        "# Оцениваем вероятности для классов с помощью метода predict_proba на тестовых данных\n",
        "y_pred_proba = clf.predict_proba(X_test)\n",
        "# Оцениваем вероятности для классов с помощью метода predict_proba на тренировочных данных\n",
        "# Они понадобятся для сравнения и потом построим по ним графики для наглядности\n",
        "y_pred_train_proba = clf.predict_proba(X_train)\n",
        "# в данном случае очень неудобно смотреть на цифры в научном формате, убираем его\n",
        "np.set_printoptions(suppress=True)\n",
        "print(y_pred_proba)"
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.99907083 0.00092917]\n",
            " [0.99970479 0.00029521]\n",
            " [0.99971785 0.00028215]\n",
            " ...\n",
            " [0.99971785 0.00028215]\n",
            " [0.9993178  0.0006822 ]\n",
            " [0.98753902 0.01246098]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TDx5-YlMe_Hk",
        "outputId": "00da6154-e833-4272-e693-96a46df4d66a"
      },
      "source": [
        "# оставляем в нашем массиве только вероятности для класса 1 (мошеннические операции)\n",
        "# они нам собственно и нужны\n",
        "y_pred_proba = y_pred_proba[:, 1]\n",
        "# то же самое для тренировочных данных\n",
        "y_pred_train_proba = y_pred_train_proba[:, 1]\n",
        "print(y_pred_proba)"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.00092917 0.00029521 0.00028215 ... 0.00028215 0.0006822  0.01246098]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W9bybsKAfpvo",
        "outputId": "b2d2e183-e9f4-4f39-91c4-e270f50a535e"
      },
      "source": [
        "# импортируем нужную нам метрику, в данном случае - roc_auc_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "# вычисляем метрику AUC на тренировочных данных\n",
        "AUC_train = roc_auc_score(y_train, y_pred_train_proba)\n",
        "# вычисляем метрику AUC на тестовых данных\n",
        "AUC_test = roc_auc_score(y_test, y_pred_proba)\n",
        "print(f'На тренировчных данных расчитанный AUC train = {AUC_train}')\n",
        "print(f'На тестовых данных расчитанный AUC = {AUC_test}')\n",
        "print(f'На тренировочных данных значение AUC больше чем на тестовых? - {\"Да!\" if AUC_train > AUC_test else \"Нет\"}')"
      ],
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "На тренировчных данных расчитанный AUC train = 0.9703527882554751\n",
            "На тестовых данных расчитанный AUC = 0.9462664156037156\n",
            "На тренировочных данных значение AUC больше чем на тестовых? - Да!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "G9ut8EbNgJG3",
        "outputId": "70b7be25-d6be-40f5-da3b-caca423d0dc0"
      },
      "source": [
        "# попробуем визуализировать результат\n",
        "# построим графики roc кривых для тренировочных и тестовых данных\n",
        "from sklearn.metrics import roc_curve\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba, pos_label=1)\n",
        "fpr_train, tpr_train, thresholds = roc_curve(y_train, y_pred_train_proba, pos_label=1)\n",
        "\n",
        "plt.rcParams['figure.figsize'] = 5, 5\n",
        "\n",
        "plt.plot(fpr, tpr, color='blue', alpha = 0.5, label = 'Test')\n",
        "plt.plot(fpr_train, tpr_train, color='red', alpha = 0.5, label = 'Train')\n",
        "plt.plot([0, 1], [0, 1], color='grey', linestyle='dashed')\n",
        "\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC curve')\n",
        "plt.legend(loc = 'best')\n",
        "plt.show()\n"
      ],
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}